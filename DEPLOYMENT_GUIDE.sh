#!/bin/bash
# Quick deployment guide for F5-TTS-Vi

cat << 'EOF'
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         F5-TTS Vietnamese - Deployment Guide                 â•‘
â•‘         One Codebase, Three Deployment Modes                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“‹ AVAILABLE MODES:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODE 1: Local Testing (Port 7860)                           â”‚
â”‚ Best for: Quick testing, development                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Start:  ./start_local.sh                                     â”‚
â”‚ Test:   ./test_api.sh 7860                                   â”‚
â”‚ Config: F5_TTS_API_URL=http://localhost:7860                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODE 2: Docker Production (Port 8000)                        â”‚
â”‚ Best for: Production on your own server                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Build:  docker build -t f5-tts-api:latest -f Dockerfile.optimized --network=host . â”‚
â”‚ Run:    docker run -d --name f5-tts-api \
            --gpus all \
            -p 8000:8000 \
            -v $(pwd)/sample:/workspace/sample \
            -v $(pwd)/output:/workspace/output \
            --restart unless-stopped \
              f5-tts-api:latest                             
â”‚ Test:   ./test_api.sh 8000                                   â”‚
â”‚ Config: F5_TTS_API_URL=http://localhost:8000                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODE 3: RunPod Serverless (Cloud)                           â”‚
â”‚ Best for: Scalable cloud deployment, pay-per-use            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Push to Docker Hub:                                       â”‚
â”‚    docker tag f5-tts-api tlong94/f5-tts-vi:optimized      â”‚
â”‚    docker push tlong94/f5-tts-vi:optimized                  â”‚
â”‚                                                              â”‚
â”‚ 2. Create RunPod Endpoint:                                   â”‚
â”‚    - Image: tlong94/f5-tts-vi:optimized                     â”‚
â”‚    - GPU: RTX 3090/4090 (12GB+)                             â”‚
â”‚    - Workers: Min 0, Max 3+ (scale as needed)               â”‚
â”‚    - Note: Max workers can be 10, 50, 100+ depending on    â”‚
â”‚      your traffic and budget. Start with 3 for testing.    â”‚
â”‚                                                              â”‚
â”‚ 3. Configure Next.js:                                        â”‚
â”‚    RUNPOD_API_KEY=your_key                                   â”‚
â”‚    RUNPOD_ENDPOINT_ID=your_endpoint_id                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ”§ QUICK SETUP:

1. Start API (choose one):
   ./start_local.sh              # Port 7860 (testing)
   ./start_docker_mode.sh        # Port 8000 (production)

2. Test API:
   ./test_api.sh 7860            # Test local
   ./test_api.sh 8000            # Test docker

3. Update Next.js config:
   cd /home/dtlong/Starter-Prisma-Pro
   
   # For local/docker (edit .env):
   F5_TTS_API_URL=http://localhost:7860  # or 8000
   
   # For RunPod (edit .env):
   RUNPOD_API_KEY=rpa_xxxxx
   RUNPOD_ENDPOINT_ID=xxxxx

4. Restart Next.js:
   npm run dev

ðŸ“ ARCHITECTURE:

All modes share the same Flask API (flask_tts_api_optimized.py):
- Handles TTS processing
- Single job queue
- Progress tracking
- GPU optimization

Differences:
- Local/Docker: Direct API calls
- RunPod: API + Handler wrapper (returns base64 audio)

ðŸŽ¯ RECOMMENDED WORKFLOW:

Development:
  1. Use MODE 1 (port 7860) for quick testing
  2. Test changes with ./test_api.sh 7860

Production (Own Server):
  1. Build Docker image
  2. Run on port 8000
  3. Deploy to production server

Production (Cloud):
  1. Push to Docker Hub
  2. Deploy on RunPod
  3. Enable RunPod in orchestrator

ðŸ“š FULL DOCUMENTATION: README.md

EOF
